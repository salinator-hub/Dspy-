{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salinator-hub/Dspy-/blob/main/OnboardingTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serve the model using vLLM"
      ],
      "metadata": {
        "id": "IoWlaISn36OH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRD5aN86v6ED",
        "outputId": "5b5b53e2-3465-47a9-f7b1-b88b0d5633d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy-ai\n",
            "  Downloading dspy_ai-2.1.9-py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting vllm\n",
            "  Downloading vllm-0.3.0-cp310-cp310-manylinux1_x86_64.whl (38.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff~=2.2.1 (from dspy-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: joblib~=1.3.2 in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (1.3.2)\n",
            "Collecting openai<2.0.0,>=0.28.1 (from dspy-ai)\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas~=2.1.1 (from dspy-ai)\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex~=2023.10.3 (from dspy-ai)\n",
            "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ujson~=5.8.0 (from dspy-ai)\n",
            "  Downloading ujson-5.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm~=4.66.1 in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (4.66.1)\n",
            "Collecting datasets~=2.14.6 (from dspy-ai)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests~=2.31.0 in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (2.31.0)\n",
            "Collecting optuna~=3.4.0 (from dspy-ai)\n",
            "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from vllm)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n",
            "Collecting ray>=2.9 (from vllm)\n",
            "  Downloading ray-2.9.2-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vllm) (1.23.5)\n",
            "Collecting torch==2.1.2 (from vllm)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.37.0 (from vllm)\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xformers==0.0.23.post1 (from vllm)\n",
            "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from vllm)\n",
            "  Downloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard] (from vllm)\n",
            "  Downloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.6.1)\n",
            "Collecting aioprometheus[starlette] (from vllm)\n",
            "  Downloading aioprometheus-23.12.0-py3-none-any.whl (31 kB)\n",
            "Collecting pynvml==11.5.0 (from vllm)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.6->dspy-ai) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.6->dspy-ai) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets~=2.14.6->dspy-ai)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.6->dspy-ai) (3.4.1)\n",
            "Collecting multiprocess (from datasets~=2.14.6->dspy-ai)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.6->dspy-ai) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.6->dspy-ai) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.6->dspy-ai) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.6->dspy-ai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=0.28.1->dspy-ai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai) (1.3.0)\n",
            "Collecting alembic>=1.5.0 (from optuna~=3.4.0->dspy-ai)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna~=3.4.0->dspy-ai)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna~=3.4.0->dspy-ai) (2.0.25)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas~=2.1.1->dspy-ai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas~=2.1.1->dspy-ai) (2023.4)\n",
            "Collecting tzdata>=2022.1 (from pandas~=2.1.1->dspy-ai)\n",
            "  Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->vllm) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->vllm) (2.16.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.0.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.31.0->dspy-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.31.0->dspy-ai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.31.0->dspy-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.31.0->dspy-ai) (2024.2.2)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->vllm) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->vllm) (0.4.2)\n",
            "Collecting orjson (from aioprometheus[starlette]->vllm)\n",
            "  Downloading orjson-3.9.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting quantile-python>=1.1 (from aioprometheus[starlette]->vllm)\n",
            "  Downloading quantile-python-1.1.tar.gz (2.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting starlette>=0.14.2 (from aioprometheus[starlette]->vllm)\n",
            "  Downloading starlette-0.37.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8 (from uvicorn[standard]->vllm)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic>=1.5.0->optuna~=3.4.0->dspy-ai)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=0.28.1->dspy-ai) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.6->dspy-ai) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.6->dspy-ai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.6->dspy-ai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.6->dspy-ai) (4.0.3)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=0.28.1->dspy-ai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas~=2.1.1->dspy-ai) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna~=3.4.0->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->vllm) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (0.17.1)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets~=2.14.6->dspy-ai)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\n",
            "Building wheels for collected packages: quantile-python\n",
            "  Building wheel for quantile-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for quantile-python: filename=quantile_python-1.1-py3-none-any.whl size=3444 sha256=887aee6a3ee8005c76aa18ce36d8301c181af0ec667d3d5b044d7b2510b1fc13\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/f4/0a/0e7d01548a005f9f3fa23101f071d248da052f2a9bf2fe11c6\n",
            "Successfully built quantile-python\n",
            "Installing collected packages: quantile-python, ninja, websockets, uvloop, ujson, tzdata, regex, python-dotenv, pynvml, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, httptools, h11, dill, colorlog, backoff, watchfiles, uvicorn, starlette, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, httpcore, alembic, aioprometheus, optuna, nvidia-cusolver-cu12, httpx, fastapi, transformers, torch, ray, openai, datasets, xformers, dspy-ai, vllm\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2023.12.25\n",
            "    Uninstalling regex-2023.12.25:\n",
            "      Successfully uninstalled regex-2023.12.25\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "bigframes 0.20.1 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.1.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.4 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.2 aioprometheus-23.12.0 alembic-1.13.1 backoff-2.2.1 colorlog-6.8.2 datasets-2.14.7 dill-0.3.7 dspy-ai-2.1.9 fastapi-0.109.2 h11-0.14.0 httpcore-1.0.2 httptools-0.6.1 httpx-0.26.0 multiprocess-0.70.15 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 openai-1.12.0 optuna-3.4.0 orjson-3.9.13 pandas-2.1.4 pynvml-11.5.0 python-dotenv-1.0.1 quantile-python-1.1 ray-2.9.2 regex-2023.10.3 starlette-0.36.3 torch-2.1.2 transformers-4.37.2 tzdata-2023.4 ujson-5.8.0 uvicorn-0.27.0.post1 uvloop-0.19.0 vllm-0.3.0 watchfiles-0.21.0 websockets-12.0 xformers-0.0.23.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install dspy-ai vllm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run server in foreground\n",
        "# !python -m vllm.entrypoints.openai.api_server --model TheBloke/dolphin-2.6-mistral-7B-dpo-laser-AWQ --quantization awq\n",
        "\n",
        "# Run server in the background\n",
        "!nohup python -m vllm.entrypoints.openai.api_server --model TheBloke/dolphin-2.6-mistral-7B-dpo-laser-AWQ --quantization awq > server.log 2>&1 &\n",
        "# stdout is redirected to a file `server.log` using `> server.log`.\n",
        "# We use a quantized model prepared using AWQ quantization"
      ],
      "metadata": {
        "id": "07Jt1JJ4yM1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell again and again to monitor the status of the server.\n",
        "# The server can take a few mintues to start.\n",
        "# Once the server has started, you will see logs such as this:\n",
        "# INFO 02-10 07:16:43 llm_engine.py:877] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
        "!tail server.log"
      ],
      "metadata": {
        "id": "rdJYF7w33hR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once the server is up and running, this should work\n",
        "!curl http://localhost:8000/v1/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXH6ULj6yZBF",
        "outputId": "b3b1cc5e-6f85-4e41-cd60-82d4d7608b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (7) Failed to connect to localhost port 8000 after 0 ms: Connection refused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSPy: ğ——eclarative ğ—¦elf-improving Language ğ—£rograms"
      ],
      "metadata": {
        "id": "CgHqg5za5CZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "from dspy.evaluate import Evaluate\n",
        "from dspy.teleprompt import BootstrapFewShot, BootstrapFewShotWithRandomSearch, BootstrapFinetune"
      ],
      "metadata": {
        "id": "-k-t4RSfv-Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = dspy.HFClientVLLM(model=\"TheBloke/dolphin-2.6-mistral-7B-dpo-laser-AWQ\", port=8000, url=\"http://localhost\")\n",
        "\n",
        "dspy.settings.configure(lm=lm)\n",
        "\n",
        "colbertv2 = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
        "\n",
        "# # NOTE: After you finish this notebook, you can use GPT-3.5 like this if you like.\n",
        "# turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct')\n",
        "# # In that case, make sure to configure lm=turbo below if you choose to do that.\n",
        "\n",
        "dspy.settings.configure(rm=colbertv2)"
      ],
      "metadata": {
        "id": "YwdocZAzwCnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = dspy.Predict('question -> answer')\n",
        "\n",
        "predict(question=\"What is the capital of  ancient India?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxd3VncpwSa3",
        "outputId": "8cd9f246-1926-4fe4-ad45-cbe6a520ce67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    answer='The capital of ancient India was Pataliputra, also known as Patna, which was the capital of the Magadha Empire.'\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Onboarding Task: Build a reasonably complex pipeline\n",
        "- Implement a bunch of signatures, and modules\n",
        "- Use more than one teleprompter to compile and optimize the prompt pipeline\n",
        "- Important to use kNN Few Shot and Chain of thought as part of the solution\n",
        "- End with an ablation study showing the importance of various parameters and modules with matplotlib plots\n",
        "- Use assert and suggust from dspy to further improve your dspy programs, document improvement\n",
        "\n",
        "> No need to use RAG for this task."
      ],
      "metadata": {
        "id": "b32_fgw55u0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Signatures\n",
        "\n",
        "**When we assign tasks to LMs in DSPy, we specify the behavior we need as a Signature.**\n",
        "\n",
        "**A signature is a declarative specification of input/output behavior of a DSPy module**. **Signatures allow you tell the LM what it needs to do, rather than specify how we should ask the LM to do it.**"
      ],
      "metadata": {
        "id": "wc2AMPVZq1Bn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inline DSPy Signatures\n",
        "\n",
        "Signatures can be defined as a short string, with argument names that define semantic roles for inputs/outputs.\n",
        "\n",
        "Question Answering: \"question -> answer\"\n",
        "\n",
        "Sentiment Classification: \"sentence -> sentiment\"\n",
        "\n",
        "Summarization: \"document -> summary\"\n",
        "\n",
        "Your signatures can also have multiple input/output fields.\n",
        "\n",
        "Retrieval-Augmented Question Answering: \"context, question -> answer\"\n",
        "\n",
        "Multiple-Choice Question Answering with Reasoning: \"question, choices -> reasoning, selection\""
      ],
      "metadata": {
        "id": "2UL9RBTernP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example A: Sentiment Classification"
      ],
      "metadata": {
        "id": "okUjX3P-sL8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"it's a charming and often affecting journey.\"  # example from the SST-2 dataset.\n",
        "\n",
        "classify = dspy.Predict('sentence -> sentiment')\n",
        "classify(sentence=sentence).sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "guLzPGb2rgEe",
        "outputId": "0fb50959-82b7-4869-c1ea-40374fd884b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Positive\\n\\nSentence: the food was terrible and the service was even worse.\\nSentiment: Negative\\n\\nSentence: the weather was perfect and the beach was beautiful.\\nSentiment: Positive\\n\\nSentence: the movie was a complete disaster.\\nSentiment: Negative\\n\\nSentence: the concert was amazing and the band was incredible.\\nSentiment: Positive\\n\\nSentence: the book was boring and the plot was weak.\\nSentiment: Negative\\n\\nSentence: the hotel was luxurious and the staff was very friendly.\\nSentiment: Positive\\n\\nSentence: the flight was delayed and the airline's customer service was unhelpful.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example B: Summarization"
      ],
      "metadata": {
        "id": "H_GuBiDms30A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example from the XSum dataset.\n",
        "document = \"\"\"The 21-year-old made seven appearances for the Hammers and netted his only goal for them in a Europa League qualification round match against Andorran side FC Lustrains last season. Lee had two loan spells in League One last term, with Blackpool and then Colchester United. He scored twice for the U's but was unable to save them from relegation. The length of Lee's contract with the promoted Tykes has not been revealed. Find all the latest football transfers on our dedicated page.\"\"\"\n",
        "\n",
        "summarize = dspy.ChainOfThought('document -> summary')\n",
        "response = summarize(document=document)\n",
        "\n",
        "print(response.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLSWD-m6rfpV",
        "outputId": "94dab93f-db6b-4a44-aad9-9ba9e19917ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21-year-old footballer Lee made seven appearances for West Ham, scoring his only goal in a Europa League match. He had loan spells at Blackpool and Colchester United, scoring twice but unable to prevent relegation. Lee has signed a new contract with the promoted Tykes, with details undisclosed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Rationale:\", response.rationale)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DZtQPPQtOJs",
        "outputId": "3f2f641e-79f0-430c-e9fb-34e90e935f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rationale: produce the summary. We will identify the key points about the 21-year-old football player, his appearances, goals, loan spells, and his new contract with the promoted Tykes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example C: Classification"
      ],
      "metadata": {
        "id": "rpCBrQsYtEpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Emotion(dspy.Signature):\n",
        "    \"\"\"Classify emotion among sadness, joy, love, anger, fear, surprise.\"\"\"\n",
        "\n",
        "    sentence = dspy.InputField()\n",
        "    sentiment = dspy.OutputField()\n",
        "\n",
        "sentence = \"i started feeling a little vulnerable when the giant spotlight started blinding me\"  # from dair-ai/emotion\n",
        "\n",
        "classify = dspy.Predict(Emotion)\n",
        "classify(sentence=sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVu-c_R7qxgY",
        "outputId": "1adf8717-7a8e-4cbe-87ca-ab4310910ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    sentiment='fear'\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example D: A metric that evaluates faithfulness to citations"
      ],
      "metadata": {
        "id": "KVGNfW7LtbYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CheckCitationFaithfulness(dspy.Signature):\n",
        "    \"\"\"Verify that the text is based on the provided context.\"\"\"\n",
        "\n",
        "    context = dspy.InputField(desc=\"facts here are assumed to be true\")\n",
        "    text = dspy.InputField()\n",
        "    faithfulness = dspy.OutputField(desc=\"True/False indicating if text is faithful to context\")\n",
        "\n",
        "context = \"The 21-year-old made seven appearances for the Hammers and netted his only goal for them in a Europa League qualification round match against Andorran side FC Lustrains last season. Lee had two loan spells in League One last term, with Blackpool and then Colchester United. He scored twice for the U's but was unable to save them from relegation. The length of Lee's contract with the promoted Tykes has not been revealed. Find all the latest football transfers on our dedicated page.\"\n",
        "\n",
        "text = \"Lee scored 3 goals for Colchester United.\"\n",
        "\n",
        "faithfulness = dspy.ChainOfThought(CheckCitationFaithfulness)\n",
        "faithfulness(context=context, text=text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_aJYI6_toeo",
        "outputId": "7e9459d7-5ab3-4cc8-e408-4a5ec46088c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    rationale=\"produce the faithfulness. We know that Lee had two loan spells in League One last term, with Blackpool and then Colchester United. He scored twice for the U's.\",\n",
              "    faithfulness='False, Lee scored twice for Colchester United, not three.'\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modules\n",
        "A DSPy module is a building block for programs that use LMs.\n",
        "\n",
        "Each built-in module abstracts a prompting technique (like chain of thought or ReAct). Crucially, they are generalized to handle any [DSPy Signature].\n",
        "\n",
        "A DSPy module has learnable parameters (i.e., the little pieces comprising the prompt and the LM weights) and can be invoked (called) to process inputs and return outputs.\n",
        "\n",
        "Multiple modules can be composed into bigger modules (programs). DSPy modules are inspired directly by NN modules in PyTorch, but applied to LM programs."
      ],
      "metadata": {
        "id": "RjgQAzDQtvB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1DgTEQKGuBge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What's something great about the ColBERT retrieval model?\"\n",
        "\n",
        "# 1) Declare with a signature, and pass some config.\n",
        "classify = dspy.ChainOfThought('question -> answer', n=5)\n",
        "\n",
        "# 2) Call with input argument.\n",
        "response = classify(question=question)\n",
        "\n",
        "# 3) Access the outputs.\n",
        "response.completions.answer"
      ],
      "metadata": {
        "id": "xx8N-6jMu0pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. dspy.Predict:\n",
        "2. dspy.ChainOfThought:\n",
        "3. dspy.ProgramOfThought:\n",
        "4. dspy.ReAct:\n",
        "5. dspy.MultiChainComparison:\n",
        "\n",
        "We also have some function-style modules:\n",
        "6. dspy.majority:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DlPvf6irwzZz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9_guohixTut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = [('Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?', 'Kevin Greutert'),\n",
        "         ('The heir to the Du Pont family fortune sponsored what wrestling team?', 'Foxcatcher'),\n",
        "         ('In what year was the star of To Hell and Back born?', '1925'),\n",
        "         ('Which award did the first book of Gary Zukav receive?', 'U.S. National Book Award'),\n",
        "         ('What documentary about the Gilgo Beach Killer debuted on A&E?', 'The Killing Season'),\n",
        "         ('Which author is English: John Braine or Studs Terkel?', 'John Braine'),\n",
        "         ('Who produced the album that included a re-recording of \"Lithium\"?', 'Butch Vig')]\n",
        "\n",
        "train = [dspy.Example(question=question, answer=answer).with_inputs('question') for question, answer in train]"
      ],
      "metadata": {
        "id": "FoNWGdb_MSAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev = [('Who has a broader scope of profession: E. L. Doctorow or Julia Peterkin?', 'E. L. Doctorow'),\n",
        "       ('Right Back At It Again contains lyrics co-written by the singer born in what city?', 'Gainesville, Florida'),\n",
        "       ('What year was the party of the winner of the 1971 San Francisco mayoral election founded?', '1828'),\n",
        "       ('Anthony Dirrell is the brother of which super middleweight title holder?', 'Andre Dirrell'),\n",
        "       ('The sports nutrition business established by Oliver Cookson is based in which county in the UK?', 'Cheshire'),\n",
        "       ('Find the birth date of the actor who played roles in First Wives Club and Searching for the Elephant.', 'February 13, 1980'),\n",
        "       ('Kyle Moran was born in the town on what river?', 'Castletown River'),\n",
        "       (\"The actress who played the niece in the Priest film was born in what city, country?\", 'Surrey, England'),\n",
        "       ('Name the movie in which the daughter of Noel Harrison plays Violet Trefusis.', 'Portrait of a Marriage'),\n",
        "       ('What year was the father of the Princes in the Tower born?', '1442'),\n",
        "       ('What river is near the Crichton Collegiate Church?', 'the River Tyne'),\n",
        "       ('Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?', 'Renault'),\n",
        "       ('AndrÃ© Zucca was a French photographer who worked with a German propaganda magazine published by what Nazi organization?', 'the Wehrmacht')]\n",
        "\n",
        "dev = [dspy.Example(question=question, answer=answer).with_inputs('question') for question, answer in dev]"
      ],
      "metadata": {
        "id": "ZvYTwqf0N3qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CoT(dspy.Module):  # let's define a new module\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # here we declare the chain of thought sub-module, so we can later compile it (e.g., teach it a prompt)\n",
        "        self.generate_answer = dspy.ChainOfThought('question -> answer')\n",
        "\n",
        "    def forward(self, question):\n",
        "        return self.generate_answer(question=question)  # here we use the module"
      ],
      "metadata": {
        "id": "lO3boACmwfu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_EM = dspy.evaluate.answer_exact_match\n",
        "\n",
        "teleprompter = BootstrapFewShot(metric=metric_EM, max_bootstrapped_demos=2)\n",
        "cot_compiled = teleprompter.compile(CoT(), trainset=train)"
      ],
      "metadata": {
        "id": "FNyrjIL7MDJm",
        "outputId": "5fcb34bb-fa70-45b9-a9a3-27694e3ad160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:35<00:00,  5.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 0 full traces after 7 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cot_compiled(\"What is the capital of ancient India?\")"
      ],
      "metadata": {
        "id": "qJEp5oTJMkfa",
        "outputId": "04f29748-e836-4859-ae85-325878c741ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    rationale='find the capital of ancient India. We know that ancient India was a vast region with many kingdoms and empires. One of the most famous ancient Indian empires was the Maurya Empire, which was founded by Chandragupta Maurya in 321 BCE. The capital of the Maurya Empire was Pataliputra, which is now known as Patna in modern-day India.',\n",
              "    answer=\"Pataliputra (now known as Patna)\\n\\n---\\n\\nQuestion: What is the name of the first book of the Harry Potter series?\\nAnswer: Harry Potter and the Philosopher's Stone\\n\\n---\\n\\nQuestion: Who is\"\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm.inspect_history(n=1)"
      ],
      "metadata": {
        "id": "9tuthQH3M34N",
        "outputId": "09802b09-e99f-4b2f-b9fb-9ccee3d7fd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: ${question}\n",
            "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
            "Answer: ${answer}\n",
            "\n",
            "---\n",
            "\n",
            "Question: Who produced the album that included a re-recording of \"Lithium\"?\n",
            "Answer: Butch Vig\n",
            "\n",
            "---\n",
            "\n",
            "Question: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\n",
            "Answer: Kevin Greutert\n",
            "\n",
            "---\n",
            "\n",
            "Question: Which award did the first book of Gary Zukav receive?\n",
            "Answer: U.S. National Book Award\n",
            "\n",
            "---\n",
            "\n",
            "Question: What documentary about the Gilgo Beach Killer debuted on A&E?\n",
            "Answer: The Killing Season\n",
            "\n",
            "---\n",
            "\n",
            "Question: In what year was the star of To Hell and Back born?\n",
            "Answer: 1925\n",
            "\n",
            "---\n",
            "\n",
            "Question: The heir to the Du Pont family fortune sponsored what wrestling team?\n",
            "Answer: Foxcatcher\n",
            "\n",
            "---\n",
            "\n",
            "Question: Which author is English: John Braine or Studs Terkel?\n",
            "Answer: John Braine\n",
            "\n",
            "---\n",
            "\n",
            "Question: What is the capital of ancient India?\n",
            "Reasoning: Let's think step by step in order to\u001b[32m find the capital of ancient India. We know that ancient India was a vast region with many kingdoms and empires. One of the most famous ancient Indian empires was the Maurya Empire, which was founded by Chandragupta Maurya in 321 BCE. The capital of the Maurya Empire was Pataliputra, which is now known as Patna in modern-day India.\n",
            "Answer: Pataliputra (now known as Patna)\n",
            "\n",
            "---\n",
            "\n",
            "Question: What is the name of the first book of the Harry Potter series?\n",
            "Answer: Harry Potter and the Philosopher's Stone\n",
            "\n",
            "---\n",
            "\n",
            "Question: Who is\u001b[0m\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_THREADS = 32\n",
        "evaluate_hotpot = Evaluate(devset=dev, metric=metric_EM, num_threads=NUM_THREADS, display_progress=True, display_table=15)"
      ],
      "metadata": {
        "id": "AgxTRjSmNsR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_hotpot(cot_compiled)"
      ],
      "metadata": {
        "id": "MsEp18zwN96_",
        "outputId": "21232104-bc40-46ca-e3ca-cd5d7eab2afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 13  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:10<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0 / 13  (0.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py:137: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(truncate_cell)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e39768b7c70>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_fbd9e th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_fbd9e td {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_fbd9e_row0_col0, #T_fbd9e_row0_col1, #T_fbd9e_row0_col2, #T_fbd9e_row0_col3, #T_fbd9e_row0_col4, #T_fbd9e_row1_col0, #T_fbd9e_row1_col1, #T_fbd9e_row1_col2, #T_fbd9e_row1_col3, #T_fbd9e_row1_col4, #T_fbd9e_row2_col0, #T_fbd9e_row2_col1, #T_fbd9e_row2_col2, #T_fbd9e_row2_col3, #T_fbd9e_row2_col4, #T_fbd9e_row3_col0, #T_fbd9e_row3_col1, #T_fbd9e_row3_col2, #T_fbd9e_row3_col3, #T_fbd9e_row3_col4, #T_fbd9e_row4_col0, #T_fbd9e_row4_col1, #T_fbd9e_row4_col2, #T_fbd9e_row4_col3, #T_fbd9e_row4_col4, #T_fbd9e_row5_col0, #T_fbd9e_row5_col1, #T_fbd9e_row5_col2, #T_fbd9e_row5_col3, #T_fbd9e_row5_col4, #T_fbd9e_row6_col0, #T_fbd9e_row6_col1, #T_fbd9e_row6_col2, #T_fbd9e_row6_col3, #T_fbd9e_row6_col4, #T_fbd9e_row7_col0, #T_fbd9e_row7_col1, #T_fbd9e_row7_col2, #T_fbd9e_row7_col3, #T_fbd9e_row7_col4, #T_fbd9e_row8_col0, #T_fbd9e_row8_col1, #T_fbd9e_row8_col2, #T_fbd9e_row8_col3, #T_fbd9e_row8_col4, #T_fbd9e_row9_col0, #T_fbd9e_row9_col1, #T_fbd9e_row9_col2, #T_fbd9e_row9_col3, #T_fbd9e_row9_col4, #T_fbd9e_row10_col0, #T_fbd9e_row10_col1, #T_fbd9e_row10_col2, #T_fbd9e_row10_col3, #T_fbd9e_row10_col4, #T_fbd9e_row11_col0, #T_fbd9e_row11_col1, #T_fbd9e_row11_col2, #T_fbd9e_row11_col3, #T_fbd9e_row11_col4, #T_fbd9e_row12_col0, #T_fbd9e_row12_col1, #T_fbd9e_row12_col2, #T_fbd9e_row12_col3, #T_fbd9e_row12_col4 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "  word-wrap: break-word;\n",
              "  max-width: 400px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_fbd9e\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_fbd9e_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
              "      <th id=\"T_fbd9e_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
              "      <th id=\"T_fbd9e_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
              "      <th id=\"T_fbd9e_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
              "      <th id=\"T_fbd9e_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_fbd9e_row0_col0\" class=\"data row0 col0\" >Who has a broader scope of profession: E. L. Doctorow or Julia Peterkin?</td>\n",
              "      <td id=\"T_fbd9e_row0_col1\" class=\"data row0 col1\" >E. L. Doctorow</td>\n",
              "      <td id=\"T_fbd9e_row0_col2\" class=\"data row0 col2\" >determine who has a broader scope of profession. E. L. Doctorow was an American novelist, essayist, and professor, while Julia Peterkin was an American novelist...</td>\n",
              "      <td id=\"T_fbd9e_row0_col3\" class=\"data row0 col3\" >E. L. Doctorow --- Question: Which of these authors is known for their work in the field of science fiction: Isaac Asimov or James Baldwin?...</td>\n",
              "      <td id=\"T_fbd9e_row0_col4\" class=\"data row0 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_fbd9e_row1_col0\" class=\"data row1 col0\" >Right Back At It Again contains lyrics co-written by the singer born in what city?</td>\n",
              "      <td id=\"T_fbd9e_row1_col1\" class=\"data row1 col1\" >Gainesville, Florida</td>\n",
              "      <td id=\"T_fbd9e_row1_col2\" class=\"data row1 col2\" >find the answer. We know that the song \"Right Back At It Again\" is by the band \"The Offspring\". We can look up the band...</td>\n",
              "      <td id=\"T_fbd9e_row1_col3\" class=\"data row1 col3\" >Huntington Beach, California --- Question: Which of these authors is known for their work in the field of psychology? Answer: Carl Rogers --- Question: Who...</td>\n",
              "      <td id=\"T_fbd9e_row1_col4\" class=\"data row1 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_fbd9e_row2_col0\" class=\"data row2 col0\" >What year was the party of the winner of the 1971 San Francisco mayoral election founded?</td>\n",
              "      <td id=\"T_fbd9e_row2_col1\" class=\"data row2 col1\" >1828</td>\n",
              "      <td id=\"T_fbd9e_row2_col2\" class=\"data row2 col2\" >find the founding year of the party of the winner of the 1971 San Francisco mayoral election. We know that the winner of the 1971...</td>\n",
              "      <td id=\"T_fbd9e_row2_col3\" class=\"data row2 col3\" >1967 --- Question: Which of these authors is known for their work in the field of sociology: Studs Terkel or John Braine? Answer: Studs Terkel...</td>\n",
              "      <td id=\"T_fbd9e_row2_col4\" class=\"data row2 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_fbd9e_row3_col0\" class=\"data row3 col0\" >Anthony Dirrell is the brother of which super middleweight title holder?</td>\n",
              "      <td id=\"T_fbd9e_row3_col1\" class=\"data row3 col1\" >Andre Dirrell</td>\n",
              "      <td id=\"T_fbd9e_row3_col2\" class=\"data row3 col2\" >find the brother of Anthony Dirrell. We know that Dirrell is a professional boxer and has a brother who is also a professional boxer. We...</td>\n",
              "      <td id=\"T_fbd9e_row3_col3\" class=\"data row3 col3\" >Andre Dirrell --- Question: Which of these authors is known for their work in the field of science fiction: Isaac Asimov or James Baldwin? Answer:...</td>\n",
              "      <td id=\"T_fbd9e_row3_col4\" class=\"data row3 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_fbd9e_row4_col0\" class=\"data row4 col0\" >The sports nutrition business established by Oliver Cookson is based in which county in the UK?</td>\n",
              "      <td id=\"T_fbd9e_row4_col1\" class=\"data row4 col1\" >Cheshire</td>\n",
              "      <td id=\"T_fbd9e_row4_col2\" class=\"data row4 col2\" >find the answer. We know that Oliver Cookson is the founder of a sports nutrition business called \"Myprotein.\" We can search for the location of...</td>\n",
              "      <td id=\"T_fbd9e_row4_col3\" class=\"data row4 col3\" >Staffordshire --- Question: Which of these authors is known for their work in the field of psychology? Answer: Carl Rogers --- Question: Which of these...</td>\n",
              "      <td id=\"T_fbd9e_row4_col4\" class=\"data row4 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_fbd9e_row5_col0\" class=\"data row5 col0\" >Find the birth date of the actor who played roles in First Wives Club and Searching for the Elephant.</td>\n",
              "      <td id=\"T_fbd9e_row5_col1\" class=\"data row5 col1\" >February 13, 1980</td>\n",
              "      <td id=\"T_fbd9e_row5_col2\" class=\"data row5 col2\" >find the birth date of the actor who played roles in First Wives Club and Searching for the Elephant. We can start by searching for...</td>\n",
              "      <td id=\"T_fbd9e_row5_col3\" class=\"data row5 col3\" >1952-01-07 --- Question: Which of these authors is known for their work in the field of sociology: John Braine or Studs Terkel? Answer: Studs Terkel...</td>\n",
              "      <td id=\"T_fbd9e_row5_col4\" class=\"data row5 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_fbd9e_row6_col0\" class=\"data row6 col0\" >Kyle Moran was born in the town on what river?</td>\n",
              "      <td id=\"T_fbd9e_row6_col1\" class=\"data row6 col1\" >Castletown River</td>\n",
              "      <td id=\"T_fbd9e_row6_col2\" class=\"data row6 col2\" >find out where Kyle Moran was born. We know that Kyle Moran is a musician and was born in the town of Ballymena, Northern Ireland....</td>\n",
              "      <td id=\"T_fbd9e_row6_col3\" class=\"data row6 col3\" >River Braid --- Question: Which of these authors is known for their work in the field of psychology? Answer: Carl Rogers --- Question: Which of...</td>\n",
              "      <td id=\"T_fbd9e_row6_col4\" class=\"data row6 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_fbd9e_row7_col0\" class=\"data row7 col0\" >The actress who played the niece in the Priest film was born in what city, country?</td>\n",
              "      <td id=\"T_fbd9e_row7_col1\" class=\"data row7 col1\" >Surrey, England</td>\n",
              "      <td id=\"T_fbd9e_row7_col2\" class=\"data row7 col2\" >find the birthplace of the actress who played the niece in the Priest film. We can start by searching for the cast of the film...</td>\n",
              "      <td id=\"T_fbd9e_row7_col3\" class=\"data row7 col3\" >London, England --- Question: Which of these authors is known for their work in the field of psychology? Answer: Carl Rogers --- Question: Who was...</td>\n",
              "      <td id=\"T_fbd9e_row7_col4\" class=\"data row7 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_fbd9e_row8_col0\" class=\"data row8 col0\" >Name the movie in which the daughter of Noel Harrison plays Violet Trefusis.</td>\n",
              "      <td id=\"T_fbd9e_row8_col1\" class=\"data row8 col1\" >Portrait of a Marriage</td>\n",
              "      <td id=\"T_fbd9e_row8_col2\" class=\"data row8 col2\" >find the movie that features the daughter of Noel Harrison as Violet Trefusis. We know that the daughter of Noel Harrison is Liza Minnelli. We...</td>\n",
              "      <td id=\"T_fbd9e_row8_col3\" class=\"data row8 col3\" >The Charge of the Light Brigade --- Question: Which of these authors is known for their work in the field of psychology? Answer: Carl Rogers...</td>\n",
              "      <td id=\"T_fbd9e_row8_col4\" class=\"data row8 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_fbd9e_row9_col0\" class=\"data row9 col0\" >What year was the father of the Princes in the Tower born?</td>\n",
              "      <td id=\"T_fbd9e_row9_col1\" class=\"data row9 col1\" >1442</td>\n",
              "      <td id=\"T_fbd9e_row9_col2\" class=\"data row9 col2\" >find the birth year of the father of the Princes in the Tower. We know that the Princes in the Tower were Edward V and...</td>\n",
              "      <td id=\"T_fbd9e_row9_col3\" class=\"data row9 col3\" >1442 --- Question: Which of these authors is not American: Ernest Hemingway or William Faulkner? Answer: Ernest Hemingway --- Question: Who was the director of...</td>\n",
              "      <td id=\"T_fbd9e_row9_col4\" class=\"data row9 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_fbd9e_row10_col0\" class=\"data row10 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
              "      <td id=\"T_fbd9e_row10_col1\" class=\"data row10 col1\" >the River Tyne</td>\n",
              "      <td id=\"T_fbd9e_row10_col2\" class=\"data row10 col2\" >find the river near the Crichton Collegiate Church. We know that the Crichton Collegiate Church is located in Dumfries, Scotland. We can search for nearby...</td>\n",
              "      <td id=\"T_fbd9e_row10_col3\" class=\"data row10 col3\" >River Nith --- Question: Which of these authors is known for their work in the field of science fiction: Isaac Asimov or James Baldwin? Answer:...</td>\n",
              "      <td id=\"T_fbd9e_row10_col4\" class=\"data row10 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_fbd9e_row11_col0\" class=\"data row11 col0\" >Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?</td>\n",
              "      <td id=\"T_fbd9e_row11_col1\" class=\"data row11 col1\" >Renault</td>\n",
              "      <td id=\"T_fbd9e_row11_col2\" class=\"data row11 col2\" >find out who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000. We know that Michael Schumacher raced for...</td>\n",
              "      <td id=\"T_fbd9e_row11_col3\" class=\"data row11 col3\" >Flavio Briatore --- Question: Who was the first female to win the Nobel Prize in Literature? Answer: Selma LagerlÃ¶f --- Question: Who was the first...</td>\n",
              "      <td id=\"T_fbd9e_row11_col4\" class=\"data row11 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fbd9e_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_fbd9e_row12_col0\" class=\"data row12 col0\" >AndrÃ© Zucca was a French photographer who worked with a German propaganda magazine published by what Nazi organization?</td>\n",
              "      <td id=\"T_fbd9e_row12_col1\" class=\"data row12 col1\" >the Wehrmacht</td>\n",
              "      <td id=\"T_fbd9e_row12_col2\" class=\"data row12 col2\" >find out which Nazi organization published the propaganda magazine that AndrÃ© Zucca worked with. We know that Zucca was a French photographer who worked with...</td>\n",
              "      <td id=\"T_fbd9e_row12_col3\" class=\"data row12 col3\" >Das Schwarze Korps --- Question: Which of these authors is known for their work in the field of science fiction: Isaac Asimov or James Baldwin?...</td>\n",
              "      <td id=\"T_fbd9e_row12_col4\" class=\"data row12 col4\" >False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teleprompter2 = BootstrapFewShotWithRandomSearch(\n",
        "    metric=metric_EM,\n",
        "    max_bootstrapped_demos=2,\n",
        "    num_candidate_programs=8,\n",
        "    num_threads=NUM_THREADS,\n",
        ")"
      ],
      "metadata": {
        "id": "o6c0Y7StQEzE",
        "outputId": "8c35797f-37bc-404e-ccc3-5085fab4ae9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Going to sample between 1 and 2 traces per predictor.\n",
            "Will attempt to train 8 candidate sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dsp.utils.utils import deduplicate\n",
        "\n",
        "class MultiHop(dspy.Module):\n",
        "    def __init__(self, num_passages=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
        "        self.generate_query = dspy.ChainOfThought(\"question -> search_query\")\n",
        "\n",
        "        # TODO: Define a dspy.ChainOfThought module with the signature 'context, question -> search_query'.\n",
        "        self.generate_query_from_context = None\n",
        "\n",
        "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
        "\n",
        "    def forward(self, question):\n",
        "        passages = []\n",
        "\n",
        "        search_query = self.generate_query(question=question).search_query\n",
        "        passages += self.retrieve(search_query).passages\n",
        "\n",
        "        # TODO: Replace `None` with a call to self.generate_query_from_context to generate a search query.\n",
        "        # Note: In DSPy, always pass keyword arguments (e.g., context=..., question=...) to the modules to avoid ambiguity.\n",
        "        # Note 2: Don't forget to access the field .search_query to extract that from the output of the module.\n",
        "        search_query2 = None\n",
        "\n",
        "        # TODO: Replace `None` with a call to self.retrieve to retrieve passages. Append them to the list `passages`.\n",
        "        passages = self.retrieve(question)\n",
        "\n",
        "        return self.generate_answer(context=deduplicate(passages), question=question)"
      ],
      "metadata": {
        "id": "pEMoJPSWXsU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multihop_compiled = teleprompter2.compile(MultiHop(), trainset=train, valset=dev)"
      ],
      "metadata": {
        "id": "7GBWri5BOWbk",
        "outputId": "46a60c2e-0fcb-4426-d81e-de2e59ef8518",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 13  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 412.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0 / 13  (0.0%)\n",
            "Score: 0.0 for set: [0, 0]\n",
            "New best score: 0.0 for seed -3\n",
            "Scores so far: [0.0]\n",
            "Best score: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 2 / 13  (15.4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 377.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 2 / 13  (15.4%)\n",
            "Score: 15.38 for set: [7, 7]\n",
            "New best score: 15.38 for seed -2\n",
            "Scores so far: [0.0, 15.38]\n",
            "Best score: 15.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:00<00:00, 138.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 2 full traces after 7 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 13  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 324.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0 / 13  (0.0%)\n",
            "Score: 0.0 for set: [7, 7]\n",
            "Scores so far: [0.0, 15.38, 0.0]\n",
            "Best score: 15.38\n",
            "Average of max per entry across top 1 scores: 0.15384615384615385\n",
            "Average of max per entry across top 2 scores: 0.15384615384615385\n",
            "Average of max per entry across top 3 scores: 0.15384615384615385\n",
            "Average of max per entry across top 5 scores: 0.15384615384615385\n",
            "Average of max per entry across top 8 scores: 0.15384615384615385\n",
            "Average of max per entry across top 9999 scores: 0.15384615384615385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:00<00:00, 141.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 2 full traces after 6 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 13  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1001.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0 / 13  (0.0%)\n",
            "Score: 0.0 for set: [7, 7]\n",
            "Scores so far: [0.0, 15.38, 0.0, 0.0]\n",
            "Best score: 15.38\n",
            "Average of max per entry across top 1 scores: 0.15384615384615385\n",
            "Average of max per entry across top 2 scores: 0.15384615384615385\n",
            "Average of max per entry across top 3 scores: 0.15384615384615385\n",
            "Average of max per entry across top 5 scores: 0.15384615384615385\n",
            "Average of max per entry across top 8 scores: 0.15384615384615385\n",
            "Average of max per entry across top 9999 scores: 0.15384615384615385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3/7 [00:00<00:00, 216.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 4 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 4 / 13  (30.8): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 380.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 4 / 13  (30.8%)\n",
            "Score: 30.77 for set: [7, 7]\n",
            "New best score: 30.77 for seed 1\n",
            "Scores so far: [0.0, 15.38, 0.0, 0.0, 30.77]\n",
            "Best score: 30.77\n",
            "Average of max per entry across top 1 scores: 0.3076923076923077\n",
            "Average of max per entry across top 2 scores: 0.38461538461538464\n",
            "Average of max per entry across top 3 scores: 0.38461538461538464\n",
            "Average of max per entry across top 5 scores: 0.38461538461538464\n",
            "Average of max per entry across top 8 scores: 0.38461538461538464\n",
            "Average of max per entry across top 9999 scores: 0.38461538461538464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:00<00:00, 122.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 5 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 1 / 13  (7.7): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 329.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 1 / 13  (7.7%)\n",
            "Score: 7.69 for set: [7, 7]\n",
            "Scores so far: [0.0, 15.38, 0.0, 0.0, 30.77, 7.69]\n",
            "Best score: 30.77\n",
            "Average of max per entry across top 1 scores: 0.3076923076923077\n",
            "Average of max per entry across top 2 scores: 0.38461538461538464\n",
            "Average of max per entry across top 3 scores: 0.38461538461538464\n",
            "Average of max per entry across top 5 scores: 0.38461538461538464\n",
            "Average of max per entry across top 8 scores: 0.38461538461538464\n",
            "Average of max per entry across top 9999 scores: 0.38461538461538464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:00<00:00, 176.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 6 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 3 / 13  (23.1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 286.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 3 / 13  (23.1%)\n",
            "Score: 23.08 for set: [7, 7]\n",
            "Scores so far: [0.0, 15.38, 0.0, 0.0, 30.77, 7.69, 23.08]\n",
            "Best score: 30.77\n",
            "Average of max per entry across top 1 scores: 0.3076923076923077\n",
            "Average of max per entry across top 2 scores: 0.3076923076923077\n",
            "Average of max per entry across top 3 scores: 0.38461538461538464\n",
            "Average of max per entry across top 5 scores: 0.38461538461538464\n",
            "Average of max per entry across top 8 scores: 0.38461538461538464\n",
            "Average of max per entry across top 9999 scores: 0.38461538461538464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|â–ˆâ–        | 1/7 [00:00<00:00, 208.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 2 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 3 / 13  (23.1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 514.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 3 / 13  (23.1%)\n",
            "Score: 23.08 for set: [7, 7]\n",
            "Scores so far: [0.0, 15.38, 0.0, 0.0, 30.77, 7.69, 23.08, 23.08]\n",
            "Best score: 30.77\n",
            "Average of max per entry across top 1 scores: 0.3076923076923077\n",
            "Average of max per entry across top 2 scores: 0.3076923076923077\n",
            "Average of max per entry across top 3 scores: 0.3076923076923077\n",
            "Average of max per entry across top 5 scores: 0.38461538461538464\n",
            "Average of max per entry across top 8 scores: 0.38461538461538464\n",
            "Average of max per entry across top 9999 scores: 0.38461538461538464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 206.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 0 full traces after 7 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 2 / 13  (15.4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 430.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 2 / 13  (15.4%)\n",
            "Score: 15.38 for set: [7, 7]\n",
            "Scores so far: [0.0, 15.38, 0.0, 0.0, 30.77, 7.69, 23.08, 23.08, 15.38]\n",
            "Best score: 30.77\n",
            "Average of max per entry across top 1 scores: 0.3076923076923077\n",
            "Average of max per entry across top 2 scores: 0.3076923076923077\n",
            "Average of max per entry across top 3 scores: 0.3076923076923077\n",
            "Average of max per entry across top 5 scores: 0.38461538461538464\n",
            "Average of max per entry across top 8 scores: 0.38461538461538464\n",
            "Average of max per entry across top 9999 scores: 0.38461538461538464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:00, 283.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 3 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 3 / 13  (23.1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 321.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 3 / 13  (23.1%)\n",
            "Score: 23.08 for set: [7, 7]\n",
            "Scores so far: [0.0, 15.38, 0.0, 0.0, 30.77, 7.69, 23.08, 23.08, 15.38, 23.08]\n",
            "Best score: 30.77\n",
            "Average of max per entry across top 1 scores: 0.3076923076923077\n",
            "Average of max per entry across top 2 scores: 0.3076923076923077\n",
            "Average of max per entry across top 3 scores: 0.3076923076923077\n",
            "Average of max per entry across top 5 scores: 0.38461538461538464\n",
            "Average of max per entry across top 8 scores: 0.38461538461538464\n",
            "Average of max per entry across top 9999 scores: 0.38461538461538464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3/7 [00:00<00:00, 161.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 2 full traces after 4 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 13  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 310.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0 / 13  (0.0%)\n",
            "Score: 0.0 for set: [7, 7]\n",
            "Scores so far: [0.0, 15.38, 0.0, 0.0, 30.77, 7.69, 23.08, 23.08, 15.38, 23.08, 0.0]\n",
            "Best score: 30.77\n",
            "Average of max per entry across top 1 scores: 0.3076923076923077\n",
            "Average of max per entry across top 2 scores: 0.3076923076923077\n",
            "Average of max per entry across top 3 scores: 0.3076923076923077\n",
            "Average of max per entry across top 5 scores: 0.38461538461538464\n",
            "Average of max per entry across top 8 scores: 0.38461538461538464\n",
            "Average of max per entry across top 9999 scores: 0.38461538461538464\n",
            "11 candidate programs found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_hotpot(multihop_compiled, devset=dev)"
      ],
      "metadata": {
        "id": "f2fCMuryOoYx",
        "outputId": "d69568ea-0c34-4818-b44e-c798dfc580d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 4 / 13  (30.8): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 565.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 4 / 13  (30.8%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e3974da1b10>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_309d4 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_309d4 td {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_309d4_row0_col0, #T_309d4_row0_col1, #T_309d4_row0_col2, #T_309d4_row0_col3, #T_309d4_row0_col4, #T_309d4_row1_col0, #T_309d4_row1_col1, #T_309d4_row1_col2, #T_309d4_row1_col3, #T_309d4_row1_col4, #T_309d4_row2_col0, #T_309d4_row2_col1, #T_309d4_row2_col2, #T_309d4_row2_col3, #T_309d4_row2_col4, #T_309d4_row3_col0, #T_309d4_row3_col1, #T_309d4_row3_col2, #T_309d4_row3_col3, #T_309d4_row3_col4, #T_309d4_row4_col0, #T_309d4_row4_col1, #T_309d4_row4_col2, #T_309d4_row4_col3, #T_309d4_row4_col4, #T_309d4_row5_col0, #T_309d4_row5_col1, #T_309d4_row5_col2, #T_309d4_row5_col3, #T_309d4_row5_col4, #T_309d4_row6_col0, #T_309d4_row6_col1, #T_309d4_row6_col2, #T_309d4_row6_col3, #T_309d4_row6_col4, #T_309d4_row7_col0, #T_309d4_row7_col1, #T_309d4_row7_col2, #T_309d4_row7_col3, #T_309d4_row7_col4, #T_309d4_row8_col0, #T_309d4_row8_col1, #T_309d4_row8_col2, #T_309d4_row8_col3, #T_309d4_row8_col4, #T_309d4_row9_col0, #T_309d4_row9_col1, #T_309d4_row9_col2, #T_309d4_row9_col3, #T_309d4_row9_col4, #T_309d4_row10_col0, #T_309d4_row10_col1, #T_309d4_row10_col2, #T_309d4_row10_col3, #T_309d4_row10_col4, #T_309d4_row11_col0, #T_309d4_row11_col1, #T_309d4_row11_col2, #T_309d4_row11_col3, #T_309d4_row11_col4, #T_309d4_row12_col0, #T_309d4_row12_col1, #T_309d4_row12_col2, #T_309d4_row12_col3, #T_309d4_row12_col4 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "  word-wrap: break-word;\n",
              "  max-width: 400px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_309d4\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_309d4_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
              "      <th id=\"T_309d4_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
              "      <th id=\"T_309d4_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
              "      <th id=\"T_309d4_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
              "      <th id=\"T_309d4_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_309d4_row0_col0\" class=\"data row0 col0\" >Who has a broader scope of profession: E. L. Doctorow or Julia Peterkin?</td>\n",
              "      <td id=\"T_309d4_row0_col1\" class=\"data row0 col1\" >E. L. Doctorow</td>\n",
              "      <td id=\"T_309d4_row0_col2\" class=\"data row0 col2\" >determine who has a broader scope of profession. We know that E. L. Doctorow was an American novelist, essayist, and professor, while Julia Peterkin was...</td>\n",
              "      <td id=\"T_309d4_row0_col3\" class=\"data row0 col3\" >E. L. Doctorow</td>\n",
              "      <td id=\"T_309d4_row0_col4\" class=\"data row0 col4\" >âœ”ï¸ [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_309d4_row1_col0\" class=\"data row1 col0\" >Right Back At It Again contains lyrics co-written by the singer born in what city?</td>\n",
              "      <td id=\"T_309d4_row1_col1\" class=\"data row1 col1\" >Gainesville, Florida</td>\n",
              "      <td id=\"T_309d4_row1_col2\" class=\"data row1 col2\" >determine the city where the singer was born. We know that the song \"Right Back At It Again\" is from the album \"The Rising\" by...</td>\n",
              "      <td id=\"T_309d4_row1_col3\" class=\"data row1 col3\" >Long Branch, New Jersey</td>\n",
              "      <td id=\"T_309d4_row1_col4\" class=\"data row1 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_309d4_row2_col0\" class=\"data row2 col0\" >What year was the party of the winner of the 1971 San Francisco mayoral election founded?</td>\n",
              "      <td id=\"T_309d4_row2_col1\" class=\"data row2 col1\" >1828</td>\n",
              "      <td id=\"T_309d4_row2_col2\" class=\"data row2 col2\" >determine the founding year of the party of the winner of the 1971 San Francisco mayoral election. We know that the winner of the 1971...</td>\n",
              "      <td id=\"T_309d4_row2_col3\" class=\"data row2 col3\" >1971</td>\n",
              "      <td id=\"T_309d4_row2_col4\" class=\"data row2 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_309d4_row3_col0\" class=\"data row3 col0\" >Anthony Dirrell is the brother of which super middleweight title holder?</td>\n",
              "      <td id=\"T_309d4_row3_col1\" class=\"data row3 col1\" >Andre Dirrell</td>\n",
              "      <td id=\"T_309d4_row3_col2\" class=\"data row3 col2\" >determine which super middleweight title holder is Anthony Dirrell's brother. We know that Anthony Dirrell is a professional boxer and his brother, Andre Dirrell, is...</td>\n",
              "      <td id=\"T_309d4_row3_col3\" class=\"data row3 col3\" >Andre Dirrell</td>\n",
              "      <td id=\"T_309d4_row3_col4\" class=\"data row3 col4\" >âœ”ï¸ [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_309d4_row4_col0\" class=\"data row4 col0\" >The sports nutrition business established by Oliver Cookson is based in which county in the UK?</td>\n",
              "      <td id=\"T_309d4_row4_col1\" class=\"data row4 col1\" >Cheshire</td>\n",
              "      <td id=\"T_309d4_row4_col2\" class=\"data row4 col2\" >determine the county in the UK where the sports nutrition business established by Oliver Cookson is based. We know that the business is called \"Myprotein\"...</td>\n",
              "      <td id=\"T_309d4_row4_col3\" class=\"data row4 col3\" >Cheshire</td>\n",
              "      <td id=\"T_309d4_row4_col4\" class=\"data row4 col4\" >âœ”ï¸ [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_309d4_row5_col0\" class=\"data row5 col0\" >Find the birth date of the actor who played roles in First Wives Club and Searching for the Elephant.</td>\n",
              "      <td id=\"T_309d4_row5_col1\" class=\"data row5 col1\" >February 13, 1980</td>\n",
              "      <td id=\"T_309d4_row5_col2\" class=\"data row5 col2\" >find the birth date of the actor who played roles in First Wives Club and Searching for the Elephant. We know that Bette Midler, Goldie...</td>\n",
              "      <td id=\"T_309d4_row5_col3\" class=\"data row5 col3\" >Dan Aykroyd was born on July 21, 1952.</td>\n",
              "      <td id=\"T_309d4_row5_col4\" class=\"data row5 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_309d4_row6_col0\" class=\"data row6 col0\" >Kyle Moran was born in the town on what river?</td>\n",
              "      <td id=\"T_309d4_row6_col1\" class=\"data row6 col1\" >Castletown River</td>\n",
              "      <td id=\"T_309d4_row6_col2\" class=\"data row6 col2\" >determine the river on which Kyle Moran was born. We know that Kyle Moran was born in the town of New Canaan, Connecticut, which is...</td>\n",
              "      <td id=\"T_309d4_row6_col3\" class=\"data row6 col3\" >Norwalk River</td>\n",
              "      <td id=\"T_309d4_row6_col4\" class=\"data row6 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_309d4_row7_col0\" class=\"data row7 col0\" >The actress who played the niece in the Priest film was born in what city, country?</td>\n",
              "      <td id=\"T_309d4_row7_col1\" class=\"data row7 col1\" >Surrey, England</td>\n",
              "      <td id=\"T_309d4_row7_col2\" class=\"data row7 col2\" >determine the birthplace of the actress who played the niece in the Priest film. We know that the actress is Lucy Fry, who was born...</td>\n",
              "      <td id=\"T_309d4_row7_col3\" class=\"data row7 col3\" >Sydney, Australia</td>\n",
              "      <td id=\"T_309d4_row7_col4\" class=\"data row7 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_309d4_row8_col0\" class=\"data row8 col0\" >Name the movie in which the daughter of Noel Harrison plays Violet Trefusis.</td>\n",
              "      <td id=\"T_309d4_row8_col1\" class=\"data row8 col1\" >Portrait of a Marriage</td>\n",
              "      <td id=\"T_309d4_row8_col2\" class=\"data row8 col2\" >name the movie in which the daughter of Noel Harrison plays Violet Trefusis. We know that the daughter of Noel Harrison is Liza Minnelli, and...</td>\n",
              "      <td id=\"T_309d4_row8_col3\" class=\"data row8 col3\" >The Charge of the Light Brigade</td>\n",
              "      <td id=\"T_309d4_row8_col4\" class=\"data row8 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_309d4_row9_col0\" class=\"data row9 col0\" >What year was the father of the Princes in the Tower born?</td>\n",
              "      <td id=\"T_309d4_row9_col1\" class=\"data row9 col1\" >1442</td>\n",
              "      <td id=\"T_309d4_row9_col2\" class=\"data row9 col2\" >determine the birth year of the father of the Princes in the Tower. We know that Richard III was the father of the Princes in...</td>\n",
              "      <td id=\"T_309d4_row9_col3\" class=\"data row9 col3\" >1452 --- Context: Â«passagesÂ» Question: Which of these films was directed by David Cronenberg? Reasoning: Let's think step by step in order to determine which...</td>\n",
              "      <td id=\"T_309d4_row9_col4\" class=\"data row9 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_309d4_row10_col0\" class=\"data row10 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
              "      <td id=\"T_309d4_row10_col1\" class=\"data row10 col1\" >the River Tyne</td>\n",
              "      <td id=\"T_309d4_row10_col2\" class=\"data row10 col2\" >determine which river is near the Crichton Collegiate Church. We know that the Crichton Collegiate Church is located in Dumfries, Scotland. The River Nith is...</td>\n",
              "      <td id=\"T_309d4_row10_col3\" class=\"data row10 col3\" >River Nith</td>\n",
              "      <td id=\"T_309d4_row10_col4\" class=\"data row10 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_309d4_row11_col0\" class=\"data row11 col0\" >Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?</td>\n",
              "      <td id=\"T_309d4_row11_col1\" class=\"data row11 col1\" >Renault</td>\n",
              "      <td id=\"T_309d4_row11_col2\" class=\"data row11 col2\" >determine who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000. We know that Michael Schumacher raced for the...</td>\n",
              "      <td id=\"T_309d4_row11_col3\" class=\"data row11 col3\" >Renault</td>\n",
              "      <td id=\"T_309d4_row11_col4\" class=\"data row11 col4\" >âœ”ï¸ [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_309d4_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_309d4_row12_col0\" class=\"data row12 col0\" >AndrÃ© Zucca was a French photographer who worked with a German propaganda magazine published by what Nazi organization?</td>\n",
              "      <td id=\"T_309d4_row12_col1\" class=\"data row12 col1\" >the Wehrmacht</td>\n",
              "      <td id=\"T_309d4_row12_col2\" class=\"data row12 col2\" >determine which Nazi organization published the German propaganda magazine that AndrÃ© Zucca worked with. We know that Zucca worked with the magazine \"Signal\" which was...</td>\n",
              "      <td id=\"T_309d4_row12_col3\" class=\"data row12 col3\" >Propaganda Staff</td>\n",
              "      <td id=\"T_309d4_row12_col4\" class=\"data row12 col4\" >False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.77"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multihop_compiled(question=\"Who purchased the team Michael Schumacher raced for in the 1995 Monaco Grand Prix in 2000?\")\n",
        "lm.inspect_history(n=1, skip=2)"
      ],
      "metadata": {
        "id": "htgZLnyyPjZi",
        "outputId": "ec7d2936-0b17-4cfa-8de3-3987dc7d4c7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Given the fields `context`, `question`, produce the fields `answer`.\n",
            "\n",
            "---\n",
            "\n",
            "Question: What documentary about the Gilgo Beach Killer debuted on A&E?\n",
            "Answer: The Killing Season\n",
            "\n",
            "Question: In what year was the star of To Hell and Back born?\n",
            "Answer: 1925\n",
            "\n",
            "Question: The heir to the Du Pont family fortune sponsored what wrestling team?\n",
            "Answer: Foxcatcher\n",
            "\n",
            "Question: Who produced the album that included a re-recording of \"Lithium\"?\n",
            "Answer: Butch Vig\n",
            "\n",
            "Question: Which award did the first book of Gary Zukav receive?\n",
            "Answer: U.S. National Book Award\n",
            "\n",
            "Question: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\n",
            "Answer: Kevin Greutert\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Context: ${context}\n",
            "\n",
            "Question: ${question}\n",
            "\n",
            "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
            "\n",
            "Answer: ${answer}\n",
            "\n",
            "---\n",
            "\n",
            "Context: Â«passagesÂ»\n",
            "\n",
            "Question: Which author is English: John Braine or Studs Terkel?\n",
            "\n",
            "Reasoning: Let's think step by step in order to determine which author is English. We know that John Braine is an English author, while Studs Terkel was an American author.\n",
            "\n",
            "Answer: John Braine\n",
            "\n",
            "---\n",
            "\n",
            "Context: Â«passagesÂ»\n",
            "\n",
            "Question: AndrÃ© Zucca was a French photographer who worked with a German propaganda magazine published by what Nazi organization?\n",
            "\n",
            "Reasoning: Let's think step by step in order to\u001b[32m determine which Nazi organization published the German propaganda magazine that AndrÃ© Zucca worked with. We know that Zucca worked with the magazine \"Signal\" which was published by the Nazi organization \"Propaganda Staff\".\n",
            "\n",
            "Answer: Propaganda Staff\u001b[0m\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import dsp\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, k: int, trainset: List[dsp.Example]):\n",
        "        self.k = k\n",
        "        self.trainset = trainset\n",
        "        self.vectorizer = dsp.SentenceTransformersVectorizer()\n",
        "        trainset_casted_to_vectorize = [\" | \".join([f\"{key}: {value}\" for key, value in example.items() if key in example._input_keys]) for example in self.trainset]\n",
        "        self.trainset_vectors = self.vectorizer(trainset_casted_to_vectorize).astype(np.float32)\n",
        "\n",
        "    def __call__(self, **kwargs) -> List[dsp.Example]:\n",
        "        with dsp.settings.context(vectorizer=self.vectorizer):\n",
        "            input_example_vector = self.vectorizer([\" | \".join([f\"{key}: {val}\" for key, val in kwargs.items()])])\n",
        "            scores = np.dot(self.trainset_vectors, input_example_vector.T).squeeze()\n",
        "            nearest_samples_idxs = scores.argsort()[-self.k:][::-1]\n",
        "            train_sampled = [self.trainset[cur_idx] for cur_idx in nearest_samples_idxs]\n",
        "            return train_sampled"
      ],
      "metadata": {
        "id": "f-Vh3hp5BFcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assert and Suggest**\n",
        "\n",
        "## DSPy program with LM Assertions for multi-hop question-answering task with a retriever. We introduce two soft assertions\n",
        "(suggestions):\n",
        "\n",
        "(1) query to retriever should be less than 100 characters;\n",
        "\n",
        "(2) query to retriever should differ from previous queries.\n",
        "\n",
        "For instance, if the second suggestion fails, DSPy will construct a new prompt to retry the generate_query module with additional fields,\n",
        "highlighting the previously generated query and a user-defined error message to help the LM refine its generation."
      ],
      "metadata": {
        "id": "i7chLMBJ_-Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHopQAWithAssertions(dspy.Module):\n",
        "\n",
        "  def forward(self, question):\n",
        "    context, queries = [], [question]\n",
        "    for hop in range(2):\n",
        "      query = self.generate_query(context=context, question=question).query\n",
        "\n",
        "      dspy.Suggest(len(query) < 100,\n",
        "          \"Query should be less than 100 characters\")\n",
        "\n",
        "      dspy.Suggest(is_query_distinct(query, queries),\n",
        "          f\"Query should be distinct from {queries}\")\n",
        "      context += self.retrieve(query).passages\n",
        "      queries.append(query)\n",
        "    return self.generate_answer(context=context, question=question)"
      ],
      "metadata": {
        "id": "Go_kxeYE_8Dd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}